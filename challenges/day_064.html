<!doctype html>
<html lang="fr">
<head>
<meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>Jour 064 ‚Äî Clustering : K-Means</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
<style>
:root{--bg:#0f172a; --accent:#06b6d4; --muted:#94a3b8;}
*{box-sizing:border-box}body{margin:0;font-family:Inter,system-ui;background:linear-gradient(180deg,#f3f7fb,#eef7fb);color:#0b1220}
.header{background:linear-gradient(90deg,#0b3d91,#0ea5e9);color:white;padding:20px;border-radius:10px;margin:16px}
.container{max-width:1100px;margin:0 auto;padding:16px}
.page{background:white;padding:24px;border-radius:12px;box-shadow:0 12px 40px rgba(2,6,23,0.06);max-width:900px;margin:0 auto}
.page h1{margin:0 0 12px 0;font-size:2em}
.page h2{margin:24px 0 12px 0;color:#0b3d91;border-bottom:2px solid #e6f6fb;padding-bottom:8px}
.page h3{margin:20px 0 10px 0;color:#0ea5e9}
.meta{color:var(--muted);font-size:13px;margin-bottom:16px}
.analogy{background:linear-gradient(90deg,#fff7ed,#fff3e8);border-left:4px solid #f59e0b;padding:16px;border-radius:8px;margin:20px 0;font-style:italic}
.theory{background:#f8fafc;padding:16px;border-radius:8px;margin:20px 0;border:1px solid #e6eef8}
.scientist{background:white;border:1px solid #e6eef8;padding:12px;border-radius:8px;margin:10px 0}
.scientist-name{font-weight:700;color:#0b3d91}
.scientist-year{color:var(--muted);font-size:0.9em}
.code{background:#0b1220;color:#d1fae5;padding:16px;border-radius:8px;overflow:auto;font-family:monospace;margin:16px 0}
.output{background:linear-gradient(90deg,#fff7ed,#fff3e8);border-left:4px solid #f59e0b;padding:12px;border-radius:8px;margin-top:12px;color:#92400e}
.exercises{margin-top:20px;padding:16px;background:#f8fafc;border-radius:8px;border:1px solid #eef2ff}
.badge{display:inline-block;padding:4px 12px;border-radius:20px;font-size:0.85em;font-weight:600;margin:4px}
.badge-level{background:#e0f2fe;color:#0369a1}
.badge-mastery{background:#f3e8ff;color:#7c3aed}
.badge-xp{background:#fef3c7;color:#92400e}
.controls{display:flex;gap:12px;justify-content:space-between;margin-top:24px;padding-top:24px;border-top:2px solid #e6eef8}
.btn{background:var(--accent);color:white;padding:10px 16px;border-radius:8px;text-decoration:none;font-weight:600;display:inline-block}
</style>
</head>
<body>
<header class="header container">
  <div style="display:flex;justify-content:space-between;align-items:center">
    <div>
      <h1 style="margin:0;color:white">Jour 064 ‚Äî Clustering : K-Means</h1>
      <div style="font-size:0.9em;opacity:0.9">Challenge 100 Jours SymPy</div>
    </div>
    <div><a class="btn" href="index.html">‚Üê Index</a></div>
  </div>
</header>

<div class="container">
  <main class="page">
    <div class="meta">
      <span class="badge badge-level">üéØ Interm√©diaire</span>
      <span class="badge badge-mastery">üìä Avanc√©</span>
      <span class="badge badge-xp">‚≠ê +40 XP</span>
    </div>

    <h2>üåç Analogie Africaine</h2>
    <div class="analogy">Le clustering, c'est comme ranger une chambre en d√©sordre. On regroupe les objets similaires : les livres avec les livres, les jouets avec les jouets. L'algorithme trouve tout seul les cat√©gories naturelles sans qu'on lui dise quoi chercher.</div>

    <h2>üìö Th√©orie : Apprentissage Non Supervis√©</h2>
    <div class="theory">
      <p>K-Means partitionne les donn√©es en K groupes (clusters) en minimisant la distance intra-classe. C'est un algorithme it√©ratif.</p>
      <h3>Fondements Math√©matiques</h3>
      <ul><li>Centro√Øde : moyenne des points du cluster</li><li>Distance Euclidienne : d(x,y) = ||x-y||‚ÇÇ</li><li>Inertie intra-classe : Œ£ ||x - Œº_k||¬≤</li><li>Algorithme EM (Expectation-Maximization)</li><li>Vorono√Ø tessellation</li></ul>
    </div>

    <h2>üë®‚Äçüî¨ Histoire & Scientifiques</h2>
    
    <div class="scientist">
      <div class="scientist-name">Stuart Lloyd</div>
      <div class="scientist-year">1957</div>
      <div class="scientist-contribution">
        <strong>Contribution :</strong> Algorithme K-Means
        <br><em>Contexte :</em> Initialement pour la modulation par impulsions cod√©es
      </div>
    </div>
    <div class="scientist">
      <div class="scientist-name">Hugo Steinhaus</div>
      <div class="scientist-year">1956</div>
      <div class="scientist-contribution">
        <strong>Contribution :</strong> Formalisation du clustering
        <br><em>Contexte :</em> Pionnier de l'analyse math√©matique des jeux
      </div>
    </div>

    <h2>üíª Code SymPy</h2>
    <div class="code"><pre>from sympy import symbols, sqrt
x1, y1, cx, cy = symbols('x1 y1 cx cy')
# Distance au carr√© entre un point et un centro√Øde
dist_sq = (x1 - cx)**2 + (y1 - cy)**2
# Le centro√Øde optimal minimise cette distance (moyenne)
# C'est un probl√®me d'optimisation g√©om√©trique</pre></div>
    <div class="output"><strong>Sortie attendue :</strong> Minimisation de la variance</div>

    <h2>üí™ Exercices Pratiques</h2>
    <div class="exercises"><ol><li>Calculer le nouveau centro√Øde de 3 points</li><li>Pourquoi K-Means converge-t-il toujours ?</li><li>Choisir le bon K (m√©thode du coude)</li></ol></div>

    <h2>üî¨ Applications Pratiques</h2>
    <p>Segmentation client, compression d'image, d√©tection d'anomalies.</p>

    <div class="controls">
      <a class="btn" href="day_063.html">‚Üê Pr√©c√©dent</a>
      <a class="btn" href="day_065.html">Suivant ‚Üí</a>
    </div>
  </main>
</div>
</body>
</html>